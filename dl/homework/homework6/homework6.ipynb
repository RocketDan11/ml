{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'AdamX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[1;32m    127\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m--> 128\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamX\u001b[49m(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m():\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'AdamX'"
     ]
    }
   ],
   "source": [
    "#Problem 1, ViT from scratch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "image_size = 32\n",
    "patch_size = 4\n",
    "num_classes = 100\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = .0001\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "hidden_dim = 256\n",
    "mlp_dim = 512\n",
    "\n",
    "# Data preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.2675, 0.2568, 0.2761))\n",
    "])\n",
    "\n",
    "# CIFAR-100 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                           download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Patch embedding layer\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels=3, embed_dim=256):\n",
    "        super().__init__()\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, \n",
    "                            kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # [B, embed_dim, H', W']\n",
    "        x = x.flatten(2)  # [B, embed_dim, num_patches]\n",
    "        x = x.transpose(1, 2)  # [B, num_patches, embed_dim]\n",
    "        return x\n",
    "\n",
    "# Transformer Encoder\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2 = self.layer_norm1(x)\n",
    "        attention_output, _ = self.attention(x2, x2, x2)\n",
    "        x = x + attention_output\n",
    "        x2 = self.layer_norm2(x)\n",
    "        mlp_output = self.mlp(x2)\n",
    "        x = x + mlp_output\n",
    "        return x\n",
    "\n",
    "# Vision Transformer\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_classes, embed_dim, \n",
    "                 num_heads, num_layers, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(image_size, patch_size, 3, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.transformer = nn.ModuleList(\n",
    "            [TransformerEncoder(embed_dim, num_heads, mlp_dim, dropout) \n",
    "             for _ in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for transformer in self.transformer:\n",
    "            x = transformer(x)\n",
    "            \n",
    "        x = self.layer_norm(x)\n",
    "        cls_token_final = x[:, 0]\n",
    "        x = self.head(cls_token_final)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = VisionTransformer(\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    mlp_dim=mlp_dim\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(progress_bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Debug information\n",
    "            if i == 0 and epoch == 0:\n",
    "                print(f\"Input images shape: {images.shape}\")\n",
    "                print(f\"Labels shape: {labels.shape}\")\n",
    "                print(f\"Labels values: {labels[:10]}\")  # Print first 10 labels\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Debug information\n",
    "            if i == 0 and epoch == 0:\n",
    "                print(f\"Model outputs shape: {outputs.shape}\")\n",
    "                print(f\"Expected outputs shape: {torch.Size([batch_size, num_classes])}\")\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    return train_losses, train_accuracies\n",
    "\n",
    "# Test the model\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(test_loader, desc='Testing')\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar with current accuracy\n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix({'accuracy': f'{accuracy:.2f}%'})\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        final_loss = running_loss / len(test_loader)\n",
    "        final_acc = 100 * correct / total\n",
    "        \n",
    "        # Store metrics\n",
    "        test_losses.append(final_loss)\n",
    "        test_accuracies.append(final_acc)\n",
    "        \n",
    "        print(f'Final Test Loss: {final_loss:.4f}, Final Test Accuracy: {final_acc:.2f}%')\n",
    "    \n",
    "    return test_losses, test_accuracies\n",
    "\n",
    "# Visualize training and testing results\n",
    "def visualize_results(train_losses, train_accuracies, test_losses, test_accuracies):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot([len(train_losses)-1], test_losses, 'ro', label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Test Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot([len(train_accuracies)-1], test_accuracies, 'ro', label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('vit_training_results.png')\n",
    "    plt.show()\n",
    "\n",
    "# Run training and testing\n",
    "if __name__ == '__main__':\n",
    "    print(\"Training started...\")\n",
    "    train_losses, train_accuracies = train()\n",
    "    print(\"\\nTesting started...\")\n",
    "    test_losses, test_accuracies = test()\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"\\nVisualizing results...\")\n",
    "    visualize_results(train_losses, train_accuracies, test_losses, test_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 2: swin finetuning and \"from scratch\" comparison\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SwinForImageClassification, SwinConfig, AutoImageProcessor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 2e-5  # Smaller learning rate for fine-tuning\n",
    "image_size = 224  # Swin expects 224x224 input by default\n",
    "\n",
    "# Model configurations\n",
    "models_config = {\n",
    "    \"swin-tiny-pretrained\": {\n",
    "        \"name\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
    "        \"pretrained\": True,\n",
    "        \"freeze_backbone\": True\n",
    "    },\n",
    "    \"swin-small-pretrained\": {\n",
    "        \"name\": \"microsoft/swin-small-patch4-window7-224\",\n",
    "        \"pretrained\": True,\n",
    "        \"freeze_backbone\": True\n",
    "    },\n",
    "    \"swin-tiny-scratch\": {\n",
    "        \"name\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
    "        \"pretrained\": False,\n",
    "        \"freeze_backbone\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Results tracking\n",
    "results = {\n",
    "    \"model\": [],\n",
    "    \"epoch_train_time\": [],\n",
    "    \"test_accuracy\": []\n",
    "}\n",
    "\n",
    "# CIFAR-100 dataset preparation\n",
    "def prepare_data(model_name):\n",
    "    # Data preparation with proper preprocessing for Swin\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "    ])\n",
    "    \n",
    "    # CIFAR-100 dataset\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                              download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                             download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Create and configure model\n",
    "def setup_model(config):\n",
    "    if config[\"pretrained\"]:\n",
    "        print(f\"Loading pretrained {config['name']}...\")\n",
    "        model = SwinForImageClassification.from_pretrained(\n",
    "            config[\"name\"],\n",
    "            num_labels=100,  # CIFAR-100 has 100 classes\n",
    "            ignore_mismatched_sizes=True  # Allows replacing the original classifier head\n",
    "        ).to(device)\n",
    "    else:\n",
    "        print(f\"Initializing {config['name']} from scratch...\")\n",
    "        # For scratch training, initialize with the same architecture but random weights\n",
    "        swin_config = SwinConfig.from_pretrained(\n",
    "            config[\"name\"],\n",
    "            num_labels=100  # CIFAR-100 has 100 classes\n",
    "        )\n",
    "        model = SwinForImageClassification(swin_config).to(device)\n",
    "    \n",
    "    # Freeze backbone parameters if specified\n",
    "    if config[\"freeze_backbone\"]:\n",
    "        print(\"Freezing backbone parameters...\")\n",
    "        for param in model.swin.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Only the classifier head will be trained\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Configure optimizer for fine-tuning (only classifier parameters)\n",
    "        optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        print(\"Training all parameters...\")\n",
    "        # Configure optimizer for training from scratch (all parameters)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, optimizer\n",
    "\n",
    "# Training function\n",
    "def train_model(model, optimizer, train_loader, test_loader, model_name):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch_times = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        \n",
    "        for i, (images, labels) in enumerate(progress_bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            if (i+1) % 100 == 0:\n",
    "                progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch+1} training time: {epoch_time:.2f} seconds\")\n",
    "    \n",
    "    # Calculate average epoch time\n",
    "    avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
    "    \n",
    "    # Test the model\n",
    "    accuracy = test_model(model, test_loader)\n",
    "    \n",
    "    # Store results\n",
    "    results[\"model\"].append(model_name)\n",
    "    results[\"epoch_train_time\"].append(avg_epoch_time)\n",
    "    results[\"test_accuracy\"].append(accuracy)\n",
    "    \n",
    "    return avg_epoch_time, accuracy\n",
    "\n",
    "# Testing function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    for model_name, config in models_config.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {model_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        train_loader, test_loader = prepare_data(config[\"name\"])\n",
    "        \n",
    "        # Setup model\n",
    "        model, optimizer = setup_model(config)\n",
    "        \n",
    "        # Train and test model\n",
    "        avg_epoch_time, accuracy = train_model(model, optimizer, train_loader, test_loader, model_name)\n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Average epoch training time: {avg_epoch_time:.2f} seconds\")\n",
    "        print(f\"Test accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        del model, optimizer\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Create and display results table\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Save results to CSV\n",
    "    results_df.to_csv(\"swin_comparison_results.csv\", index=False)\n",
    "    print(\"Results saved to swin_comparison_results.csv\")\n",
    "    \n",
    "    # Print findings for report\n",
    "    print(\"\\nKey Findings for Report:\")\n",
    "    print(\"1. Fine-tuning vs. Training from Scratch:\")\n",
    "    ft_acc = results_df[results_df['model'] == 'swin-tiny-pretrained']['test_accuracy'].values[0]\n",
    "    scratch_acc = results_df[results_df['model'] == 'swin-tiny-scratch']['test_accuracy'].values[0]\n",
    "    print(f\"   - Accuracy difference: {ft_acc - scratch_acc:.2f}%\")\n",
    "    \n",
    "    print(\"2. Swin-Tiny vs. Swin-Small:\")\n",
    "    tiny_acc = results_df[results_df['model'] == 'swin-tiny-pretrained']['test_accuracy'].values[0]\n",
    "    small_acc = results_df[results_df['model'] == 'swin-small-pretrained']['test_accuracy'].values[0]\n",
    "    print(f\"   - Accuracy difference: {small_acc - tiny_acc:.2f}%\")\n",
    "    \n",
    "    # Note about training times\n",
    "    tiny_time = results_df[results_df['model'] == 'swin-tiny-pretrained']['epoch_train_time'].values[0]\n",
    "    small_time = results_df[results_df['model'] == 'swin-small-pretrained']['epoch_train_time'].values[0]\n",
    "    scratch_time = results_df[results_df['model'] == 'swin-tiny-scratch']['epoch_train_time'].values[0]\n",
    "    print(f\"3. Training Time Comparison:\")\n",
    "    print(f\"   - Swin-Tiny (pretrained): {tiny_time:.2f} seconds/epoch\")\n",
    "    print(f\"   - Swin-Small (pretrained): {small_time:.2f} seconds/epoch\")\n",
    "    print(f\"   - Swin-Tiny (scratch): {scratch_time:.2f} seconds/epoch\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (master-env)",
   "language": "python",
   "name": "master-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
